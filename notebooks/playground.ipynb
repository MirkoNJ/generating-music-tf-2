{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If one changes the state after it has been appended to something it will also be changed there by reference\n",
    "state = [[0,0] for x in range(10)]\n",
    "statematrix = []\n",
    "statematrix.append(state)\n",
    "state[0] = [1, 1]\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to understand the 1d convolutions done\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "inp = np.array([[[0],[1],[2],[3],[4]],[[5],[4],[3],[2],[1]]]).astype(np.float32)            # [batch size, width, in channels]\n",
    "kernel = tf.reshape(np.array([1,0,0,0,1,0,0,0,1,0,0,0,0,0,0]).astype(np.float32),[5,1,3])   # [width, in channels, out channels]\n",
    "kernel = tf.expand_dims(tf.eye(5), axis=1)\n",
    "out = tf.nn.conv1d(inp, kernel, stride=1, padding='SAME')\n",
    "print(inp.shape)\n",
    "print(kernel.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kernel)\n",
    "print(inp)\n",
    "print(out)\n",
    "kernel / 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_2 = kernel + 1\n",
    "vicinity = tf.stack([kernel, kernel_2], axis=3) #shape (5, 1, 5, 2)\n",
    "print(vicinity)\n",
    "vicinity = tf.unstack(vicinity, axis=2) # 5 arrays of shape (5, 1, 2)\n",
    "#print(vicinity)\n",
    "#vicinity = tf.concat(vicinity, axis=2) #shape (5, 1, 10)\n",
    "vicinity = tf.reshape(vicinity,[-1,2])\n",
    "print(vicinity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "vicinity = tf.unstack(vicinity, axis=2) # shape 25 arrays of shape (2048, 88, 2)\n",
    "vicinity = tf.concat(vicinity, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims(tf.tile(tf.eye(12), multiples=[(88 // 12)*2,1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tile(Time_indices, multiples=[16*88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Time = tf.reshape(tf.tile(Time_indices, multiples=[16*88]), shape=[16, 88, 128,1])\n",
    "tf.concat([x_Time%2, x_Time//2%2, x_Time//4%2, x_Time//8%2], axis=-1)[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1, 1], [2, 2], [3, 4], [5, 6]])\n",
    "print(t)\n",
    "tf.slice(t, [0,1], [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(np.arange(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.reshape(np.array(np.arange(128)), (2,2,4,8), name=None)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.slice(t, [0,0,0,0],[2, 2, 3, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import numpy as np\n",
    "\n",
    "class Lay(Layer):\n",
    "    def init(self):\n",
    "        super(Lay,self).__init__()\n",
    "\n",
    "    def build(self,inputShape):\n",
    "        print(inputShape)\n",
    "        super(Lay,self).build(inputShape)\n",
    "\n",
    "    def call(self,x):\n",
    "        return [x[:,:1],x[:,-1:]]\n",
    "\n",
    "    def compute_output_shape(self,inputShape):\n",
    "        print(\"test\")\n",
    "        return [(None,1),(None,1)]\n",
    "\n",
    "\n",
    "inp = Input((2,))\n",
    "out = Lay()(inp)\n",
    "print(type(out))\n",
    "\n",
    "out = Concatenate()(out)\n",
    "model = Model(inp,out)\n",
    "model.summary()\n",
    "\n",
    "data = np.array([[1,2],[3,4],[5,6]])\n",
    "print(model.predict(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.keras.models.load_model('test')\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.loss as ctfa\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss   = ctfa.CustomSigmoidFocalCrossEntropy(from_logits=False, gamma = 2, alpha=1)\n",
    "loss_fn = ctfa.custom_sigmoid_focal_crossentropy\n",
    "loss_1 = tfa.losses.SigmoidFocalCrossEntropy(from_logits=False, gamma = 0, alpha=0)\n",
    "loss_2 = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 0.0], [1.0, 0.0]], dtype= np.float32)\n",
    "y_pred = np.array([[0.9, 0.1], [0.9, 0.1], [0.9, 0.1], [0.8, 0.1], [0.75, 0.1]], dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true, y_pred = tf.reshape(y_true, [-1]), tf.reshape(y_pred, [-1])\n",
    "#y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(y_true, y_pred, gamma=2, alpha=1) \n",
    "# for gamma=0 and alpha=0 equal to binary cross entropy (apart from taking sum instead of mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = np.array([[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 0.0], [1.0, 0.0]], dtype= np.float32)\n",
    "y_pred_test = np.array([[0.5, 0.5], [0.5, 0.5], [0.5,0.5], [0.9, 0.5], [0.9, 0.5]], dtype= np.float32)\n",
    "y_pred_test_2 = y_true_test\n",
    "y_pred_test_3 = np.array([[1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0], [1.0, 0.0]], dtype= np.float32)\n",
    "#y_true_test, y_pred_test = tf.reshape(y_true_test, [-1]), tf.reshape(y_pred_test, [-1])\n",
    "#y_true_test, y_pred_test_2 = tf.reshape(y_true_test, [-1]), tf.reshape(y_pred_test_2, [-1])\n",
    "y_true_test, y_pred_test_3 = tf.reshape(y_true_test, [-1]), tf.reshape(y_pred_test_3, [-1])\n",
    "\n",
    "\n",
    "ctfa.custom_sigmoid_focal_crossentropy(y_true_test, y_pred_test_3, gamma = 0, alpha = 0)\n",
    "loss_2(y_true_test, y_pred_test_3)\n",
    "#, loss_fn(y_true_test, y_pred_test_3, gamma = 0, alpha = 0), loss_2(y_true_test, y_pred_test_3)\n",
    "#loss(y_true_test, y_pred_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/mirko/Documents/FHWN/MA/master_thesis/code/lstm/outputs/models/arrays/sample_9_epoch_499_20210324.npz'\n",
    "npzfile = np.load(filename)\n",
    "y_pred = npzfile['arr_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import modules.subclasses as sub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros((2,4,8,3))\n",
    "p_a = np.zeros((2,4,8,2))\n",
    "velocity = np.zeros((2,4,8,1))\n",
    "y[0,0,:,:] = np.transpose(np.array([[1,0,0,1,0,0,0,0],[1,0,0,0,0,0,0,0],[50,0,0,40,0,0,0,0]]))\n",
    "p_a[0,0,:,:] = np.transpose(np.array([[1,0,0,0,1,1,0,0],[0,0,0,0,1,0,0,0]]))\n",
    "velocity[0,0,:,:] = np.transpose(np.array([[60,60,50,40,60,70,80,100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.mean_squared_error_velocity(y, velocity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.CustomSigmoidFocalCrossEntropy(from_logits = False, \n",
    "                                           gamma = 0, \n",
    "                                           alpha = 0)(y,p_a)+sub.mean_squared_error_velocity(y, velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity = y[:,:,:,0] * velocity[:,:,:,0]\n",
    "np.sum((velocity-y[:,:,:,2]) ** 2) / np.sum(y[:,:,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
